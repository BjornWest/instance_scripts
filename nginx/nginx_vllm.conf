upstream vllm_backend {
    least_conn;
    server 127.0.0.1:8000;
    server 127.0.0.1:8001;
    
    # Keepalive connections for better performance under load
    keepalive 32;
    keepalive_requests 1000;
    keepalive_timeout 60s;
}

server {
    listen 80;

    location / {
        proxy_pass http://vllm_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header Connection "";

        # Performance tuning for LLM streaming
        proxy_buffering off;
        
        # Timeouts for batch jobs
        proxy_read_timeout 1200s;
        proxy_connect_timeout 1200s;
        proxy_send_timeout 1200s;
        
        # HTTP version for keepalive support
        proxy_http_version 1.1;
    }
}